<?xml version="1.0" encoding="utf-8"?>
<ArrayOfProgramBlock xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:xsd="http://www.w3.org/2001/XMLSchema">
  <ProgramBlock>
    <ScriptSetup>// This method is used to register this program as a "AI intent handler"
Program.Implements(
    "@AI:IntentHandler",
    API_URL
).AddOption("ApiKey", "?", "Google Gemini AI API key", "text")
 .AddOption("ModelId", DEFAULT_MODEL_ID, "Model ID", "text")
 .Run();
</ScriptSetup>
    <ScriptSource>#using System.Text.RegularExpressions

// Define constants for API paths
const string API_PROMPT_SUBMIT = "Prompt.Submit";
const string API_HISTORY_GET = "History.Get";
const string API_HISTORY_CLEAR = "History.Clear";

// Load chat history at startup
ChatSession.LoadHistory(Data.GetFolder());

// ===================================================================
// API HANDLER: Submit a new intent (user command)
// ===================================================================
Api.Handle($"{API_URL}/{API_PROMPT_SUBMIT}", (userCommand) =&gt; 
{
    // 1. Validate configuration
    string geminiApiKey = Program.Option("ApiKey").Value.Trim();
    string geminiModelId = Program.Option("ModelId").Value.Trim();
    if (geminiApiKey.Length != 39 || !geminiApiKey.StartsWith("AIzaSy") || string.IsNullOrEmpty(geminiModelId))
    {
        string error = "Gemini Intent Handler is not properly configured.";
        Program.Notify($"ERROR: {error} Please configure the program options.");
        return new ResponseText($"**Error:** {error} Go to the program's settings page to configure it.");
    }

    // 2. Build the current device list
    string allowedTypes = "Dimmer,Light,Color,Switch,Shutter,DoorLock,Thermostat";
    var devicesInGroups = Modules.Groups
        .SelectMany(
            groupName =&gt; Modules.InGroup(groupName).OfDeviceType(allowedTypes).SelectedModules,
            (groupName, module) =&gt; new { name = module.Name, group = groupName, address = module.Address, domain = module.Domain, type = module.DeviceType }
        ).ToList();
    var uniqueIdsInGroups = new HashSet&lt;(string, string)&gt;(devicesInGroups.Select(d =&gt; (d.domain, d.address)));
    var devicesWithoutGroup = Modules.OfDeviceType(allowedTypes).SelectedModules
        .Where(module =&gt; !uniqueIdsInGroups.Contains((module.Domain, module.Address)))
        .Select(module =&gt; new { name = module.Name, group = "", address = module.Address, domain = module.Domain, type = module.DeviceType });
    devicesInGroups.AddRange(devicesWithoutGroup);
    // Add Alarm System program module
    devicesInGroups.Add(new { name = "Security Alarm System", group = "Dashboard", address = "90", domain = "HomeAutomation.HomeGenie.Automation", type = ModuleTypes.Sensor });
    // Add all scripts/macros
    var scriptMacros = Modules.OfDeviceType("Program").WithParameter("Widget.DisplayModule").SelectedModules
        .Where(module =&gt; module.Address != "6" &amp;&amp; module.Address != "7" &amp;&amp; module.Properties.Find((p) =&gt; p.Name == "Widget.DisplayModule").Value == "homegenie/generic/program")
        .Select(module =&gt; new { name = module.Name, group = "", address = module.Address, domain = module.Domain, type = module.DeviceType });
    devicesInGroups.AddRange(scriptMacros);

    //string devicesList = JsonConvert.SerializeObject(devicesInGroups, Formatting.Indented);
    string devicesList = "";
    foreach (var m in devicesInGroups) {
      devicesList += $"- {m.name} | {m.type} | {m.group} | {m.domain}/{m.address}\n";
    }

    // 3. Prepare the user message with context
    var userMessage = new ChatMessage
    {
        Role = "user",
        Parts = new List&lt;MessagePart&gt; { new MessagePart { Text = userCommand as string } }
    };
    var payloadContents = new List&lt;ChatMessage&gt;(ChatSession.History);
    payloadContents.Add(userMessage);
    
    var payload = new
    {
        contents = payloadContents,
        system_instruction = new { parts = new[] { new { text = GEMINI_SYSTEM_PROMPT.Replace("%%AVAILABLE_DEVICES%%", devicesList) } } },
        generationConfig = new { temperature = 0.3 }
    };

    try
    {
        // 4. Send the request to Gemini API
        string payloadJson = JsonConvert.SerializeObject(payload);
        string geminiRequestUrl = $"https://generativelanguage.googleapis.com/v1beta/models/{geminiModelId}:generateContent?key={geminiApiKey}";
        var data = Net.WebService(geminiRequestUrl).WithTimeout(120).AddHeader("Content-Type", "application/json").Post(payloadJson).GetData();

        // 5. Process the response
        string rawGeminiResponseJson = data?.candidates?[0]?.content?.parts?[0]?.text;

        if (string.IsNullOrEmpty(rawGeminiResponseJson))
        {
            string error = "Received an empty or invalid response from the AI.";
            Program.Notify($"ERROR: {error}");
            return new ResponseText($"**Error:** {error}");
        }

        string jsonResponse = "";
        string thoughtsChain = rawGeminiResponseJson;

        string patternJsonBlock = @"```json\s*({[\s\S]*?})\s*```";
        var matchJsonBlock = Regex.Match(rawGeminiResponseJson, patternJsonBlock, RegexOptions.Singleline);

        if (matchJsonBlock.Success)
        {
            jsonResponse = matchJsonBlock.Groups[1].Value;
            thoughtsChain = rawGeminiResponseJson.Substring(0, matchJsonBlock.Index).Trim();
        }
        else
        {
            int lastBraceIndex = rawGeminiResponseJson.LastIndexOf('}');
            if (lastBraceIndex != -1)
            {
                int firstBraceIndex = rawGeminiResponseJson.LastIndexOf('{', lastBraceIndex);
                if (firstBraceIndex != -1)
                {
                    string potentialJson = rawGeminiResponseJson.Substring(firstBraceIndex);
                    try
                    {
                        JObject.Parse(potentialJson); // Validate JSON
                        jsonResponse = potentialJson;
                        thoughtsChain = rawGeminiResponseJson.Substring(0, firstBraceIndex).Trim();
                    }
                    catch (JsonReaderException) { /* Invalid block, ignored */ }
                }
            }
        }

        if (string.IsNullOrEmpty(jsonResponse))
        {
            var fallbackResponse = new {
                answer = rawGeminiResponseJson,
                commands = new string[] {}
            };
            jsonResponse = JsonConvert.SerializeObject(fallbackResponse);
            thoughtsChain = "N/A (No valid JSON block found in the response)";
            Program.Log.Warn("Could not extract a valid JSON block from AI response.");
        }

        if (!string.IsNullOrEmpty(thoughtsChain))
        {
            Program.Log.Info($"AI Thought Process: {thoughtsChain}");
        }

        string friendlyAnswer = rawGeminiResponseJson;
        try 
        {
            dynamic hgCommand = JsonConvert.DeserializeObject&lt;dynamic&gt;(jsonResponse);
            friendlyAnswer = hgCommand.answer.ToString();
            JArray commands = hgCommand.commands;

            if (commands != null)
            {
                foreach (var commandToken in commands)
                {
                    string command = commandToken.ToString();
                    if (!string.IsNullOrEmpty(command) &amp;&amp; command.ToUpper() != "NONE")
                    {
                        Program.Log.Info($"Executing command from Gemini: {command}");
                        Api.Call(command);
                    }
                }
            }
        } 
        catch (Exception parseEx) 
        {
            Program.Log.Warn($"Could not parse Gemini response as JSON. Treating as plain text. Error: {parseEx.Message}");
        }

        // 6. Update and save history
        ChatSession.History.Add(userMessage);
        var modelResponse = new ChatMessage
        {
            Role = "model",
            Parts = new List&lt;MessagePart&gt; { new MessagePart { Text = jsonResponse } }
        };
        ChatSession.History.Add(modelResponse);
        ChatSession.SaveHistory(Data.GetFolder());

        // 7. Return the friendly answer to the UI
        return new ResponseText(friendlyAnswer);
    }
    catch (Exception ex)
    {
        Program.Notify($"Error while calling Gemini API: {ex.Message}");
        return new ResponseText($"**Error:** An exception occurred while contacting the AI service. Please check the logs.\n\n`{ex.Message}`");
    }
});


// ===================================================================
// API HANDLER: Get the current chat history
// ===================================================================
Api.Handle($"{API_URL}/{API_HISTORY_GET}", (userCommand) =&gt; 
{
    return ChatSession.History;
});


// ===================================================================
// API HANDLER: Clear the chat history
// ===================================================================
Api.Handle($"{API_URL}/{API_HISTORY_CLEAR}", (userCommand) =&gt; 
{
    try
    {
        ChatSession.History.Clear();
        ChatSession.SaveHistory(Data.GetFolder());
        Program.Log.Info("Gemini Intent Handler chat history has been cleared.");
        return new ResponseStatus(Status.Ok);
    }
    catch (Exception ex)
    {
        Program.Notify($"Error clearing chat history: {ex.Message}");
        return new ResponseStatus(Status.Error, "Could not clear history.");
    }
});


// Run the program in the background
Program.GoBackground();
</ScriptSource>
    <ScriptContext>const string API_URL = "AI.IntentHandlers/Gemini";
const string DEFAULT_MODEL_ID = "gemini-flash-latest";

const string GEMINI_SYSTEM_PROMPT = """

You are a home automation assistant called HomeGenie.


**RULES**

1.  **JSON ONLY:** Your entire response MUST be ONLY a valid JSON object. No markdown. No chain thoughts.
2.  **USER'S LANGUAGE:** The "answer" field MUST be in the same language as the user's command.
3.  **COMMAND ARRAY:** The "commands" field must be an array of strings. The reply might not contains a command in which case the `commands` array must be `["NONE"]`.


**AVAILABLE DEVICES**
%%AVAILABLE_DEVICES%%


**COMMANDS LIST**
-   `Control.On`, `Control.Off`
-   `Control.Level/{value}` (value: 0-100)
-   `Control.ColorHsb/{h},{s},{v}` (h,s,v: 0.0-1.0)
-   `Thermostat.ModeSet/{mode}` (mode: "Off", "Heat", "HeatEconomy", "Cool", "CoolEconomy")
-   `Thermostat.SetPointSet/{type}/{value}` (type: "Heating", "HeatingEconomy", "Cooling", "CoolingEconomy")
-   `Control.ArmAway`
-   `Control.ArmHome`
-   `Control.Disarm`

**EXCEPTIONS**
For type `Program` commands are in the form:
-   `/api/HomeAutomation.HomeGenie/Automation/Programs.Run/&lt;numeric_address&gt;
-   `/api/HomeAutomation.HomeGenie/Automation/Programs.Break/&lt;numeric_address&gt;


**EXAMPLE**

&lt;|im_start|&gt;user
Spegni tutte le luci dello studio e poi accendi la caldaia e anche i riscaldamenti.&lt;|im_end|&gt;

&lt;|im_start|&gt;assistant
{
  "answer": "Fatto! Ho spento la luce della scrivania e Ambient nello Studio e ho acceso la caldaia.",
  "commands": [
    "/api/HomeAutomation.PhilipsHue/3/Control.Off",
    "/api/HomeAutomation.ZigBee/5/Control.Off",
    "/api/HomeAutomation.HomeGenie/S2/Control.On",
    "/api/HomeAutomation.SmartThermostat/1/Thermostat.ModeSet/Heat"
  ]
}
&lt;|im_end|&gt;

""";


// POJO

public class ChatMessage
{
    [JsonProperty("role")]
    public string Role { get; set; }

    [JsonProperty("parts")]
    public List&lt;MessagePart&gt; Parts { get; set; }
}

public class MessagePart
{
    [JsonProperty("text")]
    public string Text { get; set; }
}

static class ChatSession
{
    public static List&lt;ChatMessage&gt; History { get; set; } = new List&lt;ChatMessage&gt;();
    private static readonly string FileName = "gemini_chathistory.json";

    public static void SaveHistory(string path)
    {
        string filePath = Path.Combine(path, FileName);
        try
        {
            string json = JsonConvert.SerializeObject(History, Formatting.Indented);
            File.WriteAllText(filePath, json);
        }
        catch (Exception ex)
        {
            //Program.Log.Error($"Failed to save chat history: {ex.Message}");
        }
    }

    public static void LoadHistory(string path)
    {
        string filePath = Path.Combine(path, FileName);
        try
        {
            if (File.Exists(filePath))
            {
                string json = File.ReadAllText(filePath);
                var loadedHistory = JsonConvert.DeserializeObject&lt;List&lt;ChatMessage&gt;&gt;(json);
                if (loadedHistory != null)
                {
                    History = loadedHistory;
                }
            }
        }
        catch (Exception ex)
        {
            History = new List&lt;ChatMessage&gt;();
        }
    }
}
</ScriptContext>
    <ScriptErrors />
    <Data />
    <PackageInfo>
      <Repository>homegenie</Repository>
      <PackageId>homegenie-ml-ai</PackageId>
      <PackageVersion>1.0.3</PackageVersion>
      <Id>gemini-intent-handler</Id>
      <Version>1.0.5</Version>
      <Required>true</Required>
      <Checksum>E6A95A95F71C03A9C1326BB29387D340</Checksum>
    </PackageInfo>
    <Domain>HomeAutomation.HomeGenie.Automation</Domain>
    <Address>930</Address>
    <Name>Gemini Intent Handler</Name>
    <Description>Enables natural language control for your smart system using Google's Gemini AI.
To activate this feature, enter a valid API key.
Follow the instructions at https://aistudio.google.com/app/apikey to get a free API key.</Description>
    <Group>AI - Machine Learning</Group>
    <Features />
    <AutoRestartEnabled>false</AutoRestartEnabled>
    <Cloneable>true</Cloneable>
    <Type>csharp</Type>
    <IsEnabled>true</IsEnabled>
  </ProgramBlock>
  <ProgramBlock>
    <ScriptSetup>// This method is used to register this program as a "AI intent handler"
Program.Implements(
    "@AI:WidgetGenie",
    API_URL
).AddOption("ApiKey", "?", "Google Gemini AI API key", "text")
 .AddOption("ModelId", DEFAULT_MODEL_ID, "Model ID", "text")
 .Run();
</ScriptSetup>
    <ScriptSource>// Define constants for API paths to avoid magic strings
const string API_PROCESS = "Prompt.Submit";
const string API_HISTORY_GET = "History.Get";
const string API_HISTORY_CLEAR = "History.Clear";

// Load the chat history from disk at startup
ChatSession.LoadHistory(Data.GetFolder());

// ===================================================================
// API HANDLER: Process a new user message
// ===================================================================
Api.Handle($"{API_URL}/{API_PROCESS}", (userCommand) =&gt; 
{
    // 1. Validate configuration
    string geminiApiKey = Program.Option("ApiKey").Value.Trim();
    string geminiModelId = Program.Option("ModelId").Value.Trim();
    if (geminiApiKey.Length != 39 || !geminiApiKey.StartsWith("AIzaSy") || string.IsNullOrEmpty(geminiModelId))
    {
        string error = "Gemini AI Genie is not properly configured.";
        Program.Notify($"ERROR: {error} Please configure the program options.");
        return new ResponseText($"**Error:** {error} Go to the program's settings page to configure it.");
    }

    // 2. Prepare the user message
    var userMessage = new ChatMessage
    {
        Role = "user",
        Parts = new List&lt;MessagePart&gt; { new MessagePart { Text = userCommand as string } }
    };

    // 3. Build the payload with the full history
    var payloadContents = new List&lt;ChatMessage&gt;(ChatSession.History);
    payloadContents.Add(userMessage);
    
    var payload = new
    {
        contents = payloadContents,
        system_instruction = new
        {
            parts = new[]
            {
                new { text = GEMINI_SYSTEM_PROMPT }
            }
        },
        generationConfig = new
        {
            temperature = 0.3
        }
    };

    try
    {
        // 4. Send the request to Gemini API
        string payloadJson = JsonConvert.SerializeObject(payload);
        string geminiRequestUrl = $"https://generativelanguage.googleapis.com/v1beta/models/{geminiModelId}:generateContent?key={geminiApiKey}";
        
        var data = Net
            .WebService(geminiRequestUrl)
            .WithTimeout(120)
            .AddHeader("Content-Type", "application/json")
            .Post(payloadJson)
            .GetData();

        // 5. Process the response
        // Using `?.` (null-conditional operator) for safe navigation
        string geminiResponse = data?.candidates?[0]?.content?.parts?[0]?.text;

        if (!string.IsNullOrEmpty(geminiResponse))
        {
            // Add both user message and model response to history
            ChatSession.History.Add(userMessage);
            var modelResponse = new ChatMessage
            {
                Role = "model",
                Parts = new List&lt;MessagePart&gt; { new MessagePart { Text = geminiResponse } }
            };
            ChatSession.History.Add(modelResponse);
            ChatSession.SaveHistory(Data.GetFolder());

            return new ResponseText(geminiResponse);
        }
        else
        {
            // Handle cases where Gemini returns an empty or malformed response
            string error = "Received an empty or invalid response from the AI.";
            Program.Notify($"ERROR: {error}");
            return new ResponseText($"**Error:** {error}");
        }
    }
    catch (Exception ex)
    {
        Program.Notify($"Error while calling Gemini API: {ex.Message}");
        return new ResponseText($"**Error:** An exception occurred while contacting the AI service. Please check the logs.\n\n`{ex.Message}`");
    }
});

// ===================================================================
// API HANDLER: Get the current chat history
// ===================================================================
Api.Handle($"{API_URL}/{API_HISTORY_GET}", (userCommand) =&gt; 
{
    return ChatSession.History;
});

// ===================================================================
// API HANDLER: Clear the chat history
// ===================================================================
Api.Handle($"{API_URL}/{API_HISTORY_CLEAR}", (userCommand) =&gt; 
{
    try
    {
        // Clear the in-memory history list
        ChatSession.History.Clear();
        // Save the empty history to disk to persist the change
        ChatSession.SaveHistory(Data.GetFolder());
        
        Program.Log.Info("AI Genie chat history has been cleared.");
        return new ResponseStatus(Status.Ok);
    }
    catch (Exception ex)
    {
        Program.Notify($"Error clearing chat history: {ex.Message}");
        return new ResponseStatus(Status.Error, "Could not clear history.");
    }
});

// Run the program in the background
Program.GoBackground();</ScriptSource>
    <ScriptContext>const string API_URL = "AI.WidgetGenie/Gemini";
const string DEFAULT_MODEL_ID = "gemini-flash-latest";

const string GEMINI_SYSTEM_PROMPT = """

You are an expert AI assistant for the HomeGenie Server platform.
Your ONLY task is to help users create custom widgets based on the zuix.js framework and HomeGenie Widget API.

A widget consists of three code blocks: HTML (View), CSS (Style), and JavaScript (Controller).

## Core Concepts
- **Controller:** A class extending `ControllerInstance` with life-cycle callbacks (`onCreate`, etc.).
- **View:** Standard HTML. Elements are linked to the controller using `#field_name`.
- **Data Binding:** The `this.model()` object is a reactive proxy. Changes to `this.model().field_name` automatically update the corresponding `#field_name` element in the view.
- **Events:** Use `(click)="myFunction()"` in HTML. The function must be exposed in `onInit` via `this.declare({ myFunction: this.myFunction.bind(this) })`.

---
**API REFERENCE &amp; MANDATORY RULES**
---

**1. ZUIX.JS &amp; VIEW LOGIC -- CRITICAL RULES**
   - **FATAL: NO `{{ }}` INTERPOLATION.** Never use `{{ expression }}` in the HTML. Dynamic updates MUST be handled in the controller by updating the model.
   - **DATA BINDING IS KING:** All dynamic UI updates MUST be driven by modifying the `this.model()` object. NEVER manipulate the DOM directly with `this.field('...').html()`.
   - **PROVIDE DEFAULT VALUES IN HTML:** The HTML view MUST always contain sensible default content for preview purposes. NEVER generate empty tags for fields.
     - **WRONG:** `&lt;span #status&gt;&lt;/span&gt;`
     - **CORRECT:** `&lt;span #status&gt;Disarmed&lt;/span&gt;`

**2. HOMEGENIE API -- CRITICAL RULES**
   - **Module Fields (`field.key`):**
     - Use `this.boundModule.field('Key.Name')` to get a specific field. DO NOT USE `this.boundModule.fields.find(...)`.
     - **Available Keys:** `Status.Level`, `Status.ColorHsb`, `Sensor.Temperature`, `Conditions.IconType`, `HomeGenie.SecurityArmed` (values: "Away", "Home", "Disarmed").
     - **STATE LOGIC:** NEVER use `Status.Power`. The ON/OFF state is ALWAYS derived from `Status.Level` (a level &gt; 0 means ON).
   - **Module Commands (`control()`):**
     - **Available Commands:** `Control.On`, `Control.Off`, `Control.Level/&lt;level&gt;`, `Control.ColorHsb/&lt;h&gt;,&lt;s&gt;,&lt;b&gt;`, `Control.ArmAway`, `Control.ArmHome`, `Control.Disarm`.
     - **COMMAND LOGIC:** For ON/OFF, prefer `Control.On` and `Control.Off`.

**3. DATA FORMATTING -- CRITICAL RULES**
   - **DECIMAL SEPARATORS:** `field.value` is a string. Before `parseFloat()`, YOU MUST use `.replace(',', '.')`.

**4. ICONS -- CRITICAL RULES**
   - **SVG ICONS:** Use an `&lt;img&gt;` tag. The model contains the path, and the view binds it to the `src` attribute. Example: `&lt;img #icon src="path/to/default.svg"&gt;`.

**OUTPUT FORMATTING -- MANDATORY**
1.  **For widget requests:** Respond ONLY with three markdown code blocks (html, css, javascript).
2.  **For other requests:** Respond with conversational text.
3.  **LANGUAGE RULE:** Generated code and code comments MUST always be in English. Conversational text (e.g., for explanations or questions) MUST be in the same language as the user's last prompt.

---
**GOLDEN EXAMPLE: Switch Widget**
---

*If a user asks "create a widget for a switch", the output MUST follow this exact structure.*
When generating a complete widget, you must also provide a brief, friendly explanation of the generated code.

Your response structure MUST be as follows:
1.  A short, conversational introduction in the user's language.
2.  A clear explanation of the purpose and functionality of the widget.
3.  The three code blocks (HTML, CSS, JavaScript), clearly labeled.
4.  A concluding sentence guiding the user to copy and paste each block into the corresponding editor tab (View, Style, Controller).

**EXAMPLE OF THE DESIRED RESPONSE STRUCTURE:**

Of course! Here is a basic widget for a switch. It displays the switch's name and status, with a button to toggle it on and off. The button color will change to reflect the current state.

Simply copy and paste each of the following code blocks into the corresponding editor tabs: View (HTML), Style (CSS), and Controller (JavaScript).

Finally, remember to bind a module (the device) to this widget by clicking the settings button on the editor toolbar.

```html
&lt;div class="container"&gt;
  &lt;strong #name&gt;Unknown Switch&lt;/strong&gt;
  &lt;button (click)="toggleSwitch()"&gt;
    &lt;span class="material-symbols-outlined" #icon&gt;toggle_off&lt;/span&gt;
  &lt;/button&gt;
  &lt;span #status&gt;Off&lt;/span&gt;
&lt;/div&gt;
&lt;link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined"&gt;
```
```css
:host { display: block; }
.container { padding: 16px; display: flex; align-items: center; gap: 12px; }
button { background: none; border: none; cursor: pointer; }
.material-symbols-outlined { font-size: 48px; }
```
```javascript
class SwitchWidget extends ControllerInstance {

  isOn = false;

  onCreate() {
    // Expose the toggleSwitch method to the HTML View
    this.declare({
      toggleSwitch: this.toggleSwitch
    });

    if (!this.boundModule) {
      return;
    }

    // Subscribe to the external module's state
    const levelField = this.boundModule.field('Status.Level');
    if (levelField) {
      this.subscribe(levelField, (field) =&gt; {
        // When the external state changes, update the internal state
        this.updateState(field.value);
      });
    }
    
    // Perform an initial sync when the widget is created
    this.updateModel();
  }
  
  updateModel() {
      this.model().name = this.boundModule.name;
      const levelField = this.boundModule.field('Status.Level');
      if (levelField) {
        this.updateState(levelField.value);
      }
  }

  updateState(levelValue) {
    const level = parseFloat(levelValue.replace(',', '.'));
    this.isOn = level &gt; 0;
    
    // Update the reactive model. The view will update automatically.
    this.model().status = this.isOn ? 'On' : 'Off';
    this.model().icon = this.isOn ? 'toggle_on' : 'toggle_off';
  }

  toggleSwitch() {
    if (!this.boundModule) return;
    
    const command = this.isOn ? 'Control.Off' : 'Control.On';
    this.boundModule.control(command);
    /*
    or if you want to add a callback when the command is completed
    this.boundModule.control(command).subscribe((res) =&gt; {
      // command completed
    });
    */
  }
}
```

Now, begin.
""";


// POJO

public class ChatMessage
{
    [JsonProperty("role")]
    public string Role { get; set; }

    [JsonProperty("parts")]
    public List&lt;MessagePart&gt; Parts { get; set; }
}

public class MessagePart
{
    [JsonProperty("text")]
    public string Text { get; set; }
}

static class ChatSession
{
    public static List&lt;ChatMessage&gt; History { get; set; } = new List&lt;ChatMessage&gt;();
    private static readonly string FileName = "gemini_chathistory.json";

    public static void SaveHistory(string path)
    {
        string filePath = Path.Combine(path, FileName);
        try
        {
            string json = JsonConvert.SerializeObject(History, Formatting.Indented);
            File.WriteAllText(filePath, json);
        }
        catch (Exception ex)
        {
            //Program.Log.Error($"Failed to save chat history: {ex.Message}");
        }
    }

    public static void LoadHistory(string path)
    {
        string filePath = Path.Combine(path, FileName);
        try
        {
            if (File.Exists(filePath))
            {
                string json = File.ReadAllText(filePath);
                var loadedHistory = JsonConvert.DeserializeObject&lt;List&lt;ChatMessage&gt;&gt;(json);
                if (loadedHistory != null)
                {
                    History = loadedHistory;
                }
            }
        }
        catch (Exception ex)
        {
            History = new List&lt;ChatMessage&gt;();
        }
    }
}
</ScriptContext>
    <ScriptErrors />
    <Data />
    <PackageInfo>
      <Repository>homegenie</Repository>
      <PackageId>homegenie-ml-ai</PackageId>
      <PackageVersion>1.0.3</PackageVersion>
      <Id>gemini-widget-genie</Id>
      <Version>1.0.2</Version>
      <Required>true</Required>
      <Checksum>BEC152E192F00605C8705023C2CBB6B6</Checksum>
    </PackageInfo>
    <Domain>HomeAutomation.HomeGenie.Automation</Domain>
    <Address>931</Address>
    <Name>Gemini Widget Genie</Name>
    <Description>Your personal AI genie for widget creation. Powered by Gemini, it helps you write and debug HTML, CSS, and JavaScript code directly within the HomeGenie editor.
To activate this feature, enter a valid API key.
Follow the instructions at https://aistudio.google.com/app/apikey to get a free API key.</Description>
    <Group>AI - Machine Learning</Group>
    <Features />
    <AutoRestartEnabled>false</AutoRestartEnabled>
    <Cloneable>false</Cloneable>
    <Type>csharp</Type>
    <IsEnabled>true</IsEnabled>
  </ProgramBlock>
  <ProgramBlock>
    <ScriptSetup>Program
  .AddFeature(
    "",
    ForCameraInputType,
    InstanceSegmentation,
    "Enable instance segmentation",
    "checkbox"
  ).AddFeature(
    "",
    ForCameraInputType,
    InstanceSegmentationTrigger,
    "Comma-separated list of things (in English) that will trigger the alarm. (e.g.: cat, dog, person, backpack, suitcase)",
    "text"
  ).AddOption(
    "Yolo.ModelPath",
    Data.GetFolder() + "/yolo11n-seg.onnx",
    "Path of YOLO11 model file (.onnx)",
    "text"
  );

Program.Run();
</ScriptSetup>
    <ScriptSource>var inputModules = Modules.WithFeature(InstanceSegmentation);

// Restart program if configuration has been changed to apply new settings.
When.ModuleParameterChanged( (module, property) =&gt; {
    if (module.Instance == Program.Module &amp;&amp; property.Name.StartsWith("ConfigureOptions."))
    {
        if (Program.IsRunning) Program.Restart();
        return true;
    }
    return true;
});

var yoloModelPath = Program.Option("Yolo.ModelPath")?.Value;
if (String.IsNullOrEmpty(yoloModelPath))
{
    Program.Notify($"Configure the path of YOLO11 'segment' model (.onnx file). {OptionButtons}");
    Pause(5);
    return;
}


// For details about this implemention see
// *ML.net* and *YoloSharp* documentation


try
{
    var errorOccurred = false;
    using var detectPredictor = new YoloPredictor(yoloModelPath);
    while (Program.IsRunning)
    {
        if (inputModules.SelectedModules.Count == 0)
        {
            Pause(1);
            continue;
        }
        inputModules.Command("Camera.GetPicture").Submit((m, data) =&gt; {
            try
            {
                var result = detectPredictor.Segment((byte[])data);
                //Console.WriteLine($"Result: {result}");
                //Console.WriteLine($"Speed:  {result.Speed}");
                var module = Modules.InDomain(m.Domain).WithAddress(m.Address).Get();
                if (result.Count() &gt; 0)
                {
                    var output = new List&lt;SegmentResult&gt;();
                    // Emit "Sensor.ObjectDetect.Subject.Data" event if anything
                    // mathing the configured "TriggerDetect" list
                    // was detected in the scene.
                    string[] matchList = module
                        .Parameter( InstanceSegmentationTrigger )?.Value
                        .Split(',').Select(p =&gt; p.Trim())
                        .Where(x =&gt; !string.IsNullOrEmpty(x))
                        .ToArray();
                    if (matchList.Length &gt; 0)
                    {
                        var filtered = new List&lt;Compunet.YoloSharp.Data.Segmentation&gt;();
                        foreach (var r in result)
                        {
                            var subject = r.Name.Name;
                            if (matchList.Contains(subject))
                            {
                                filtered.Add(r);
                            }
                        }
                        if (filtered.Count &gt; 0)
                        {
                            if (module.Parameter(ObjectDetect).DecimalValue != filtered.Count) 
                            {
                                module.Emit(ObjectDetect, filtered.Count);
                            }
                            else
                            {
                                // update value and timestamp only, do not emit event
                                module.Parameter(ObjectDetect).SetData(filtered.Count);   
                            }
                            foreach (var r in filtered)
                            {
                                output.Add(new SegmentResult(){
                                    Result = r,
                                    Mask = ExtractAndApproximateContour(r.Mask, 100)
                                });
                                module.Emit(ObjectDetectSubject, r);
                            }
                        }
                        else if (module.Parameter(ObjectDetect).DecimalValue != 0 &amp;&amp; module.Parameter(ObjectDetect).IdleTime &gt; 5) 
                        {
                            module.Emit(ObjectDetect, 0);
                        }
                    }
                    else
                    {
                        foreach (var r in result)
                        {
                            output.Add(new SegmentResult(){
                                Result = r,
                                Mask = ExtractAndApproximateContour(r.Mask, 100)
                            });
                        }
                    }

                    if (output.Count &gt; 0)
                    {
                        // Emit json data for the video player (overlay data)
                        var jsonResults = JsonConvert.SerializeObject(output);
                        module.Emit(VideoPlayerWidgetOverlaySegment, jsonResults);
                    }

                }
            }
            catch (Exception e)
            {
                errorOccurred = true;
                Console.WriteLine(e.Message);
            }
        });
        if (errorOccurred)
        {
            errorOccurred = false;
            Pause(5);
        }
    }
}
catch (Exception e)
{
    Program.Notify($"Error: {e.Message} {OptionButtons}");
    Pause(5);
    return;
}
</ScriptSource>
    <ScriptContext>#using Compunet.YoloSharp.Memory

const string
OptionButtons = "[program_configure,program_disable]",
YoloModelPath = "Yolo.ModelPath",
ForCameraInputType = "Sensor:Widget.DisplayModule=homegenie/generic/camerainput",
InstanceSegmentation = "ML.InstanceSegmentation",
InstanceSegmentationTrigger = $"{InstanceSegmentation}.TriggerDetect",
ObjectDetect = "Sensor.ObjectDetect",
ObjectDetectSubject = "Sensor.ObjectDetect.Subject",
VideoPlayerWidgetOverlaySegment = "Widget.Data.VideoPlayer.Overlay.Segment";

public class SegmentResult
{
    public Compunet.YoloSharp.Data.Segmentation Result;
    public List&lt;MaskPoint&gt; Mask;
}

public class MaskPoint
{
    public float X;
    public float Y;
    public MaskPoint(float x, float y)
    {
        X = x;
        Y = y;
    }
}

public static List&lt;MaskPoint&gt; ExtractAndApproximateContour(BitmapBuffer r, int maxPoints = 25)
{
    var contour = ExtractContourPointsInternal(r);  // Get the initial contour

    if (contour.Count &lt;= maxPoints)
    {
        return contour; // No need to approximate if already within the limit
    }

    // Implement a simple approximation by taking equally spaced points
    var approximatedContour = new List&lt;MaskPoint&gt;();
    double interval = (double)contour.Count / maxPoints;
    for (int i = 0; i &lt; maxPoints - 1; i++)
    {
        int index = (int)Math.Round(i * interval); //Round for accuracy
        approximatedContour.Add(contour[index]); // Add existing point at the index
    }

    //Ensure the loop has the final item; If the last isn't added, add it
    if(approximatedContour.Last() != contour.Last()) {
            approximatedContour.Add(contour.Last());
    }

    return approximatedContour;
}


private static List&lt;MaskPoint&gt; ExtractContourPointsInternal(BitmapBuffer r)
{
    int height = r.Height;
    int width = r.Width;

    // Helper function to check if a pixel is a border pixel
    bool IsBorderPixel(BitmapBuffer mask, int x, int y)
    {
        if (x == 0 || x == width - 1 || y == 0 || y == height - 1)
        {
            return true;
        }

        return (mask[y, x - 1] &gt; 0.9 != mask[y, x] &gt; 0.9 ||
                mask[y, x + 1] &gt; 0.9 != mask[y, x] &gt; 0.9 ||
                mask[y - 1, x] &gt; 0.9 != mask[y, x] &gt; 0.9 ||
                mask[y + 1, x] &gt; 0.9 != mask[y, x] &gt; 0.9);
    }

    // Find all contour pixels
    var contourPixels = new List&lt;MaskPoint&gt;();
    for (int y = 0; y &lt; height; y++)
    {
        for (int x = 0; x &lt; width; x++)
        {
            if (r[y, x] &gt; 0.9 &amp;&amp; IsBorderPixel(r, x, y))
            {
                contourPixels.Add(new MaskPoint(x, y));
            }
        }
    }

    if (contourPixels.Count == 0)
    {
        return new List&lt;MaskPoint&gt;(); // Return empty list if no shape found
    }

    // Order the contour pixels (nearest neighbor approach)
    var contour = new List&lt;MaskPoint&gt;();
    var startPixel = contourPixels[0];
    contour.Add(startPixel);
    contourPixels.Remove(startPixel);

    var currentPixel = startPixel;

    while (contourPixels.Count &gt; 0)
    {
        var nearestNeighbor = contourPixels
            .OrderBy(p =&gt; Math.Sqrt(Math.Pow(p.X - currentPixel.X, 2) + Math.Pow(p.Y - currentPixel.Y, 2))) // Euclidean distance
            .FirstOrDefault();

        if (nearestNeighbor == null)  // No more neighbors found
        {
            break;
        }

        contour.Add(nearestNeighbor);
        contourPixels.Remove(nearestNeighbor);
        currentPixel = nearestNeighbor;
    }

    return contour;
}
</ScriptContext>
    <ScriptErrors>[]</ScriptErrors>
    <Data />
    <PackageInfo>
      <Repository>homegenie</Repository>
      <PackageId>homegenie-ml-ai</PackageId>
      <PackageVersion>1.0.3</PackageVersion>
      <Id>instance-segmentation</Id>
      <Version>1.0.1</Version>
      <Required>true</Required>
      <Checksum>C66626FF29C68B321C6563E3BB3872D6</Checksum>
    </PackageInfo>
    <Domain>HomeAutomation.HomeGenie.Automation</Domain>
    <Address>912</Address>
    <Name>Instance Segmentation</Name>
    <Description>Detect objects and their contour mask using a pre-trained YOLO11 model.
</Description>
    <Group>AI - Machine Learning</Group>
    <Features>
      <ProgramFeature>
        <FieldType>checkbox</FieldType>
        <ForDomains />
        <ForTypes>Sensor:Widget.DisplayModule=homegenie/generic/camerainput</ForTypes>
        <Property>ML.InstanceSegmentation</Property>
        <Description>Enable instance segmentation</Description>
      </ProgramFeature>
      <ProgramFeature>
        <FieldType>text</FieldType>
        <ForDomains />
        <ForTypes>Sensor:Widget.DisplayModule=homegenie/generic/camerainput</ForTypes>
        <Property>ML.InstanceSegmentation.TriggerDetect</Property>
        <Description>Comma-separated list of things (in English) that will trigger the alarm. (e.g.: cat, dog, person, backpack, suitcase)</Description>
      </ProgramFeature>
    </Features>
    <AutoRestartEnabled>false</AutoRestartEnabled>
    <Cloneable>false</Cloneable>
    <Type>csharp</Type>
    <IsEnabled>true</IsEnabled>
  </ProgramBlock>
  <ProgramBlock>
    <ScriptSetup>//
// SETUP block for the Local LLM automation program.
//
// This code is executed once when the program is enabled. Its primary roles are:
// 1. To define the user-configurable options for this program.
// 2. To specify the front-end widget used for the UI.
// 3. To define the conditions and triggers for executing the Main block.
//
// In this case, .Run() finalizes the setup and proceeds to execute the Main block immediately.
//
Program
  .AddOption(OPTION_MODEL_PATH, "", "Path to local GGUF file", "text")
  .AddOption(OPTION_MAX_TOKENS, "512", "Max Tokens (response length)", "slider:64:4096:32")
  .UseWidget("custom/examples/local-ai-chat")
  .Run();
</ScriptSetup>
    <ScriptSource>//
// MAIN block for the Local LLM automation program.
//
// This code is executed after the SETUP block. It is responsible for:
// 1. Validating user-configured options.
// 2. Initializing the LLamaSharp model, context, and chat session.
// 3. Defining an API endpoint to handle user prompts.
// 4. Managing the program's lifecycle and handling reconfiguration requests.
//

// A flag to signal that the program needs to be reloaded to apply new settings.
var reconfigureRequired = false;
// Register an event handler that listens for changes to any module parameter.
When.ModuleParameterChanged((module, parameter) =&gt; {
  // Check if the change occurred in this program and affects a configuration option.
  if (module.Instance == Program.Module &amp;&amp; parameter.Name.StartsWith("ConfigureOptions.")) {
    // Set the flag to true, which will trigger a restart of the Main block.
    reconfigureRequired = true;
  }
  return true;
});

// --- 1. VALIDATION ---
// Retrieve the model path from the program's configuration options.
var modelPath = Program.Option(OPTION_MODEL_PATH).Value;

// Check if the model path is configured.
if (String.IsNullOrEmpty(modelPath))
{
  // If not, send a notification to the UI. The '[program_configure]' tag is a special
  // command that prompts the UI to open the configuration dialog.
  Program.Notify($"LLM model path not configured.[program_configure]");
  Program.Emit(FIELD_STATUS_ERROR, "LLM model path not configured.");
}
// Check if the configured model file actually exists.
else if (!File.Exists(modelPath)) 
{
  Program.Notify($"File not found: {modelPath}.[program_configure]");
  Program.Emit(FIELD_STATUS_ERROR, $"File not found: {modelPath}");
}
else
{
  // --- 2. INITIALIZATION ---
  // If validation passes, proceed to initialize the LLM.

  // Apply the user-configured max tokens value to the inference parameters.
  LailamaInferenceParams.MaxTokens = (int)Program.Option(OPTION_MAX_TOKENS).DecimalValue;

  // Set up the model parameters, including context size and GPU layers to offload.
  var parameters = new ModelParams(modelPath)
  {
      ContextSize = PARAMS_CONTEXT_SIZE,
      GpuLayerCount = PARAMS_GPU_LAYER_SIZE
  };
 try {
  // Load the LLM weights from the specified GGUF file into memory.
  var model = LLamaWeights.LoadFromFile(parameters);
  // Create a context for the model, which holds the state of the inference.
  var context = model.CreateContext(parameters);

  // Set up an executor to run the inference in an interactive (chat) mode.
  var executor = new InteractiveExecutor(context);
  var chatHistory = new ChatHistory();

  // Create a clean, initial session state. This is used as a prototype to reset
  // the chat session without having to re-initialize the entire model.
  ChatSession prototypeSession =  ChatSession.InitializeSessionFromHistoryAsync(executor, chatHistory).GetAwaiter().GetResult();
  var resetState = prototypeSession.GetSessionState();

  // Create the main chat session that will be used for the conversation.
  ChatSession session = new ChatSession(executor);

  // Register a cleanup handler that runs when the program is stopping.
  When.ProgramStopping(() =&gt; {
      // release resources by resetting the session to its initial state.
      session.LoadSession(resetState);
      return true;
  });

  // Prepare the system prompt (defined in the Context block) to be injected into the chat history.
  var systemMessage = new ChatHistory.Message(AuthorRole.System, GetSystemPrompt()); 
  // Ensure the session is in a clean state before adding the system prompt.
  session.LoadSession(resetState);
  session.History.Messages.Add(systemMessage); 

  // --- 3. API ENDPOINT ---
  // Define an API endpoint that the front-end widget will call to send user prompts.
  Api.Handle($"{Program.Module.Domain}/{Program.Module.Address}/Process", (userInput) =&gt;  
  {
      var request = Api.Parse(userInput);
      var input = BuildUserPrompt(request.OriginalRequest);
      if (!String.IsNullOrEmpty(input))
      {
          // Asynchronously start the chat inference process with the user's message and inference parameters.
          var sessionChat = session.ChatAsync(new ChatHistory.Message(AuthorRole.User, input), LailamaInferenceParams);

          // Process the resulting token stream asynchronously.
          ProcessAsync(sessionChat, (s) =&gt; {
            // As each token (s) is generated...
            if (!string.IsNullOrEmpty(s))
            {
              // ...emit it to the front-end widget via the specified field.
              Program.Emit(FIELD_TOKENS_STREAM, s);
            }
          }).GetAwaiter().GetResult();
      }
      return new ResponseStatus(Status.Ok, "Processing: " + input);
  });

  // clear any previosuly reported error
  Program.Emit(FIELD_STATUS_ERROR, "");

 } catch (Exception e) { 


    Program.Notify($"ERROR: {e.Message} [program_configure]");
    Program.Emit(FIELD_STATUS_ERROR, e.Message);
    Pause(5);

  }

}

// Emit an empty string initially to ensure the stream field is created.
Program.Emit(FIELD_TOKENS_STREAM, "");

// --- 4. MAIN PROGRAM LOOP ---
// This loop keeps the program alive and handles the reconfiguration logic.
while (Program.IsRunning)
{
    // Check if the 'reconfigureRequired' flag was set by the event handler.
    if (reconfigureRequired)
    {
        // If true, exit the Main block. HomeGenie will then automatically re-run
        // this Main block from the top, reloading the new configuration.
        return;
    }
    // Pause for 1 second to prevent this loop from consuming 100% CPU.
    Pause(1);
}
</ScriptSource>
    <ScriptContext>/* 
||==============================================================================================
|| LLM Inference Configuration
|| These parameters control how the Large Language Model generates responses.
||
|| For detailed documentation on these parameters, see the LLamaSharp docs:
|| https://scisharp.github.io/LLamaSharp/
||==============================================================================================
*/

/**
 * The context window size in tokens.
 * This defines the model's "short-term memory," determining how much of the conversation
 * history it can consider when generating a response. 4096 is a common value for many models.
 */
const int PARAMS_CONTEXT_SIZE = 4096;

/**
 * The number of model layers to offload to the GPU.
 * Setting this to 0 disables GPU acceleration, forcing the model to run entirely on the CPU.
 * Increase this value if you have a compatible GPU to significantly improve performance. A value
 * like 32 or higher is common for GPU-accelerated inference.
 */
const int PARAMS_GPU_LAYER_SIZE = 0; // 0 = NO GPU, run on CPU only

/// &lt;summary&gt;
/// Defines the parameters for the LLM inference process.
/// These settings control the creative and technical aspects of the text generation.
/// &lt;/summary&gt;
InferenceParams LailamaInferenceParams = new InferenceParams
{
    // Configures the sampling pipeline, which controls the creativity and coherence of the output.
    SamplingPipeline = new DefaultSamplingPipeline
    {
        // Temperature: Controls randomness. Lower values (e.g., 0.2) make the output more
        // deterministic and focused, while higher values (e.g., 0.8) make it more creative and random.
        Temperature = 0.6f,

        // TopP (Nucleus Sampling): The model considers only the most likely tokens that make up the
        // cumulative probability specified here (0.95 = 95%). It helps prevent the model from
        // picking very rare or nonsensical words.
        TopP = 0.95f,

        // RepeatPenalty: Discourages the model from repeating the same words or phrases.
        // A value greater than 1.0 penalizes recently used tokens. 1.0 means no penalty.
        RepeatPenalty = 1.1f 
    },

    // The maximum number of tokens (words or parts of words) to generate in a single response.
    // This acts as a hard limit on the length of the AI's output.
    MaxTokens = 256,   // This value is controlled from the program settings UI
    
    // A list of "stop sequences." The model will immediately stop generating text if it
    // produces one of these strings. These are crucial for making the model end its turn
    // in a chat conversation and are highly specific to the model being used.
    // **This list often requires tuning based on the loaded LLM's specifications.**
    AntiPrompts = new string[]
    {
        "&lt;｜User｜&gt;",
        "&lt;｜end of sentence｜&gt;",
        "&lt;&lt;/im_end&gt;&gt;",
        "&lt;&lt;im_start&gt;&gt;",
        "&lt;&lt;/im_start&gt;&gt;",
        "&lt;think&gt;",
        "&lt;/think&gt;",
        "&lt;|im_end|&gt;",
        "&lt;|im_start|&gt;",
        "&lt;｜Assistant｜&gt;" 
    }
};

/// &lt;summary&gt;
/// Defines the System Prompt, which provides high-level instructions to the AI model.
/// The System Prompt sets the context, persona, and constraints for the entire conversation.
/// It acts as a permanent instruction that guides the model's behavior and response style.
///
/// HOW TO CREATE EFFECTIVE SYSTEM INSTRUCTIONS:
/// 1.  **Define a Persona:** Start by telling the model *what it is* (e.g., "You are an expert AI assistant...").
/// 2.  **Set the Primary Goal:** Clearly state its main objective or task ("Your ONLY task is to help users...").
/// 3.  **Provide Context:** Give it relevant background information (e.g., "...for the HomeGenie Server platform," "...based on the zuix.js framework").
/// 4.  **Establish Constraints and Rules:** Specify what the model *should not* do. Use strong, clear language like "ONLY," "DO NOT," "NEVER."
/// 5.  **Specify Output Format:** If needed, you can instruct the model on how to format its responses (e.g., "Always provide code examples in Markdown blocks.").
/// &lt;/summary&gt;
const string LAILAMA_SYSTEM_PROMPT = """

You are a concise and expert technical assistant running locally on a HomeGenie server.
Your primary tasks are to help with programming, scripting, and system administration.

- ALWAYS provide code in Markdown blocks.
- Be direct and to the point. Do not add conversational fluff.
- Your knowledge areas are: C#, JavaScript, Python, JSON, Visual Programming with Blockly and HomeGenie APIs of course.
- You can help write automation programs for the HomeGenie platform.

""";

/*
|| Program's options and emitted field
*/
const string OPTION_MODEL_PATH = "ModelPath";
const string OPTION_MAX_TOKENS = "MaxTokens";
const string FIELD_TOKENS_STREAM = "LLM.TokenStream";
const string FIELD_STATUS_ERROR = "Status.Error";

/* 
|| Utility methods
*/

string GetSystemPrompt() {
  return $"&lt;|im_start|&gt;system\n{LAILAMA_SYSTEM_PROMPT}&lt;|im_end|&gt;\n"; 
}

string BuildUserPrompt(string userInput) {
  return $"&lt;|im_start|&gt;user\n{userInput}&lt;|im_end|&gt;\n" +
         $"&lt;|im_start|&gt;assistant\n"; 
}

async Task ProcessAsync(IAsyncEnumerable&lt;string&gt; asyncEnumerable, Action&lt;string&gt; callback)
{
    await foreach (string item in asyncEnumerable)
    {
        callback(item);
    }
}
</ScriptContext>
    <ScriptErrors />
    <Data />
    <PackageInfo>
      <Repository>homegenie</Repository>
      <PackageId>homegenie-ml-ai</PackageId>
      <PackageVersion>1.0.3</PackageVersion>
      <Id>lailama</Id>
      <Version>1.0.0</Version>
      <Required>true</Required>
      <Checksum>B945C787E3FFB1EA46CF49BC5C8C512A</Checksum>
    </PackageInfo>
    <Domain>HomeAutomation.HomeGenie.Automation</Domain>
    <Address>940</Address>
    <Name>Lailama</Name>
    <Description>Run a Large Language Model (LLM) locally on your HomeGenie server. These models can be downloaded for free from platforms like Hugging Face.
Simply provide the path to a GGUF format model file. Please note that adjustments to parameters, primarily within the Context Code, may be required to ensure full compatibility with different models.</Description>
    <Group>AI - Machine Learning</Group>
    <Features />
    <AutoRestartEnabled>false</AutoRestartEnabled>
    <Cloneable>false</Cloneable>
    <Type>csharp</Type>
    <IsEnabled>true</IsEnabled>
  </ProgramBlock>
  <ProgramBlock>
    <ScriptSetup>Program
  .AddFeature(
    "",
    ForCameraInputType,
    ObjectDetection,
    "Enable objects detection",
    "checkbox"
  ).AddFeature(
    "",
    ForCameraInputType,
    ObjectDetectionTrigger,
    "Comma-separated list of things (in English) that will trigger the alarm. (e.g.: cat, dog, person, backpack, suitcase)",
    "text"
  ).AddOption(
    YoloModelPath,
    Data.GetFolder() + "/yolo11n.onnx",
    "Path of YOLO11 model file (.onnx)",
    "text"
  );

Program.Run();
</ScriptSetup>
    <ScriptSource>var inputModules = Modules.WithFeature( ObjectDetection );
// Restart program if configuration has been changed to apply new settings.
When.ModuleParameterChanged( (module, property) =&gt; {
    if (module.Instance == Program.Module &amp;&amp; property.Name.StartsWith("ConfigureOptions."))
    {
        if (Program.IsRunning) Program.Restart();
        return true;
    }
    return true;
});

var modelPath = Program.Option(YoloModelPath)?.Value;
if (String.IsNullOrEmpty(modelPath))
{
    Program.Notify($"Configure the path of YOLO11 'detect' model (.onnx file). {OptionButtons}");
    Pause(5);
    return;
}


// For details about this implemention see
// *ML.net* and *YoloSharp* documentation


try
{
    var errorOccurred = false;
    using var detectPredictor = new YoloPredictor(modelPath);
    while (Program.IsRunning)
    {
        if (inputModules.SelectedModules.Count == 0)
        {
            Pause(1);
            continue;
        }
        inputModules.Command("Camera.GetPicture").Submit((m, data) =&gt; {
            try
            {
                var result = detectPredictor.Detect((byte[])data, new YoloConfiguration { Confidence = 0.35f });
                //Console.WriteLine($"Result: {result}");
                //Console.WriteLine($"Speed:  {result.Speed}");
                var module = Modules.InDomain(m.Domain).WithAddress(m.Address).Get();
                if (result.Count() &gt; 0)
                {
                    var jsonResults = "";
                    // Emit "Sensor.ObjectDetect.Subject.Data" event if anything
                    // mathing the configured "TriggerDetect" list
                    // was detected in the scene.
                    string[] matchList = module
                        .Parameter( ObjectDetectionTrigger )?.Value
                        .Split(',').Select(p =&gt; p.Trim())
                        .Where(x =&gt; !string.IsNullOrEmpty(x))
                        .ToArray();
                    if (matchList.Length &gt; 0)
                    {
                        var filtered = new List&lt;Compunet.YoloSharp.Data.Detection&gt;();
                        foreach (var r in result)
                        {
                            var subject = r.Name.Name;
                            if (matchList.Contains(subject))
                            {
                                filtered.Add(r);
                            }
                        }
                        if (filtered.Count &gt; 0)
                        {
                            if (module.Parameter(ObjectDetect).DecimalValue != filtered.Count) 
                            {
                                module.Emit(ObjectDetect, filtered.Count);
                            }
                            else
                            {
                                // update value and timestamp only, do not emit event
                                module.Parameter(ObjectDetect).SetData(filtered.Count);   
                            }
                            foreach (var r in filtered)
                            {
                                module.Emit(ObjectDetectSubject, r);
                            }
                            jsonResults = JsonConvert.SerializeObject(filtered);
                        }
                        else if (module.Parameter(ObjectDetect).DecimalValue != 0 &amp;&amp; module.Parameter(ObjectDetect).IdleTime &gt; 5) 
                        {
                            module.Emit(ObjectDetect, 0);
                        }
                    }
                    else
                    {
                        jsonResults = JsonConvert.SerializeObject(result);
                    }

                    if (jsonResults != "")
                    {
                        // Emit json data for the video player (overlay data)
                        module.Emit(VideoPlayerWidgetOverlayDetect, jsonResults);
                    }
                }
            }
            catch (Exception e)
            {
                errorOccurred = true;
                Console.WriteLine(e.Message);
            }
        });
        if (errorOccurred)
        {
            errorOccurred = false;
            Pause(5);
        }
    }
}
catch (Exception e)
{
    Program.Notify($"Error: {e.Message} {OptionButtons}");
    Pause(5);
    return;
}
</ScriptSource>
    <ScriptContext>const string
OptionButtons = "[program_configure,program_disable]",
YoloModelPath = "Yolo.ModelPath",
ForCameraInputType = "Sensor:Widget.DisplayModule=homegenie/generic/camerainput",
ObjectDetection = "ML.ObjectDetection",
ObjectDetectionTrigger = $"{ObjectDetection}.TriggerDetect",
ObjectDetect = "Sensor.ObjectDetect",
ObjectDetectSubject = "Sensor.ObjectDetect.Subject",
VideoPlayerWidgetOverlayDetect = "Widget.Data.VideoPlayer.Overlay.Detect";
</ScriptContext>
    <ScriptErrors>[]</ScriptErrors>
    <Data />
    <PackageInfo>
      <Repository>homegenie</Repository>
      <PackageId>homegenie-ml-ai</PackageId>
      <PackageVersion>1.0.3</PackageVersion>
      <Id>object-detection</Id>
      <Version>1.0.1</Version>
      <Required>true</Required>
      <Checksum>B7CA86D23DC7EE4520DA0284DF0AC368</Checksum>
    </PackageInfo>
    <Domain>HomeAutomation.HomeGenie.Automation</Domain>
    <Address>910</Address>
    <Name>Object Detection</Name>
    <Description>Detect objects using a pre-trained YOLO11 model.
</Description>
    <Group>AI - Machine Learning</Group>
    <Features>
      <ProgramFeature>
        <FieldType>checkbox</FieldType>
        <ForDomains />
        <ForTypes>Sensor:Widget.DisplayModule=homegenie/generic/camerainput</ForTypes>
        <Property>ML.ObjectDetection</Property>
        <Description>Enable objects detection</Description>
      </ProgramFeature>
      <ProgramFeature>
        <FieldType>text</FieldType>
        <ForDomains />
        <ForTypes>Sensor:Widget.DisplayModule=homegenie/generic/camerainput</ForTypes>
        <Property>ML.ObjectDetection.TriggerDetect</Property>
        <Description>Comma-separated list of things (in English) that will trigger the alarm. (e.g.: cat, dog, person, backpack, suitcase)</Description>
      </ProgramFeature>
    </Features>
    <AutoRestartEnabled>false</AutoRestartEnabled>
    <Cloneable>false</Cloneable>
    <Type>csharp</Type>
    <IsEnabled>true</IsEnabled>
  </ProgramBlock>
  <ProgramBlock>
    <ScriptSetup>Program
  .AddFeature(
    "",
    ForCameraInputType,
    PoseDetection,
    "Enable pose tracking",
    "checkbox"
  ).AddOption(
    "Yolo.ModelPath",
    Data.GetFolder() + "/yolo11n-pose.onnx",
    "Path of YOLO11 model file (.onnx)",
    "text"
  );

Program.Run();
</ScriptSetup>
    <ScriptSource>var inputModules = Modules.WithFeature(PoseDetection);

// Restart program if configuration has been changed to apply new settings.
When.ModuleParameterChanged( (module, property) =&gt; {
  if (module.Instance == Program.Module &amp;&amp; property.Name.StartsWith("ConfigureOptions."))
  {
    if (Program.IsRunning) Program.Restart();
    return true;
  }
  return true;
});

var yoloModelPath = Program.Option("Yolo.ModelPath")?.Value;
if (String.IsNullOrEmpty(yoloModelPath))
{
    Program.Notify($"Configure the path of YOLO11 'pose' model (.onnx file). {OptionButtons}");
    Pause(5);
    return;
}


// For details about this implemention see
// *ML.net* and *YoloSharp* documentation


try
{
    var errorOccurred = false;
    using var detectPredictor = new YoloPredictor(yoloModelPath);
    while (Program.IsRunning)
    {
        if (inputModules.SelectedModules.Count == 0)
        {
            Pause(1);
            continue;
        }
        inputModules.Command("Camera.GetPicture").Submit((m, data) =&gt; {
            try
            {
                var module = Modules.InDomain(m.Domain).WithAddress(m.Address).Get();
                var result = detectPredictor.Pose((byte[])data);
                //Console.WriteLine($"Result: {result}");
                //Console.WriteLine($"Speed:  {result.Speed}");
                if (result.Count() &gt; 0)
                {
                    var jsonResults = JsonConvert.SerializeObject(result);
                    // Emit json data for the video player (overlay data)
                    module.Emit(VideoPlayerWidgetOverlayPose, jsonResults);

                    if (module.Parameter(ObjectDetect).DecimalValue != result.Count) 
                    {
                        module.Emit(ObjectDetect, result.Count);
                    }
                    else
                    {
                        // update value and timestamp only, do not emit event
                        module.Parameter(ObjectDetect).SetData(result.Count);   
                    }

                    foreach (var r in result)
                    {
                        module.Emit(ObjectDetectSubject, r);
                    }
                }
                else if (module.Parameter(ObjectDetect).DecimalValue != 0 &amp;&amp; module.Parameter(ObjectDetect).IdleTime &gt; 5) 
                {
                    module.Emit(ObjectDetect, 0);
                }
            }
            catch (Exception e)
            {
                errorOccurred = true;
                Console.WriteLine(e.Message);
            }
        });
        if (errorOccurred)
        {
            errorOccurred = false;
            Pause(5);
        }
    }
}
catch (Exception e)
{
    Program.Notify($"Error: {e.Message} {OptionButtons}");
    Pause(5);
    return;
}
</ScriptSource>
    <ScriptContext>const string
OptionButtons = "[program_configure,program_disable]",
YoloModelPath = "Yolo.ModelPath",
ForCameraInputType = "Sensor:Widget.DisplayModule=homegenie/generic/camerainput",
PoseDetection = "ML.PoseEstimation",
ObjectDetect = "Sensor.ObjectDetect",
ObjectDetectSubject = "Sensor.ObjectDetect.Subject",
VideoPlayerWidgetOverlayPose = "Widget.Data.VideoPlayer.Overlay.Pose";
</ScriptContext>
    <ScriptErrors>[]</ScriptErrors>
    <Data />
    <PackageInfo>
      <Repository>homegenie</Repository>
      <PackageId>homegenie-ml-ai</PackageId>
      <PackageVersion>1.0.3</PackageVersion>
      <Id>pose-estimation</Id>
      <Version>1.0.1</Version>
      <Required>true</Required>
      <Checksum>F67AAB91A888270A27A447F8728A1701</Checksum>
    </PackageInfo>
    <Domain>HomeAutomation.HomeGenie.Automation</Domain>
    <Address>911</Address>
    <Name>Pose estimation</Name>
    <Description>Keypoint detection via pose estimation, using custom ONNX models or the default pre-trained YOLOv11 model (human pose-specific).</Description>
    <Group>AI - Machine Learning</Group>
    <Features>
      <ProgramFeature>
        <FieldType>checkbox</FieldType>
        <ForDomains />
        <ForTypes>Sensor:Widget.DisplayModule=homegenie/generic/camerainput</ForTypes>
        <Property>ML.PoseEstimation</Property>
        <Description>Enable pose tracking</Description>
      </ProgramFeature>
    </Features>
    <AutoRestartEnabled>false</AutoRestartEnabled>
    <Cloneable>false</Cloneable>
    <Type>csharp</Type>
    <IsEnabled>true</IsEnabled>
  </ProgramBlock>
</ArrayOfProgramBlock>